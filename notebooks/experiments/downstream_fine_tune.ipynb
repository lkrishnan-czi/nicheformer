{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune Pre-trained Nicheformer Model for Downstream Tasks\n",
    "\n",
    "This notebook fine-tunes a pre-trained Nicheformer model for downstream tasks and stores predictions in an AnnData object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import anndata as ad\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "from nicheformer.models import Nicheformer\n",
    "from nicheformer.models._nicheformer_fine_tune import NicheformerFineTune\n",
    "from nicheformer.data.dataset import NicheformerDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the configuration parameters for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path': '/home/ubuntu/dev/tsv2_bladder.h5ad',  # Path to your AnnData file\n",
    "    'technology_mean_path': '/home/ubuntu/dev/sandbox/nicheformer/data/model_means/dissociated_mean_script.npy',  # Path to technology mean file\n",
    "    'checkpoint_path': '/home/ubuntu/dev/nicheformer.ckpt',  # Path to pre-trained model\n",
    "    'output_path': 'output/predictions.h5ad',  # Where to save results\n",
    "    'output_dir': 'output/checkpoints',  # Directory for checkpoints\n",
    "    \n",
    "    # Training parameters\n",
    "    'batch_size': 32,\n",
    "    'max_seq_len': 1500,\n",
    "    'aux_tokens': 30,\n",
    "    'chunk_size': 1000,\n",
    "    'num_workers': 4,\n",
    "    'precision': 32,\n",
    "    'max_epochs': 100,\n",
    "    'lr': 1e-4,\n",
    "    'warmup': 10,\n",
    "    'gradient_clip_val': 1.0,\n",
    "    'accumulate_grad_batches': 10,\n",
    "    \n",
    "    # Model parameters\n",
    "    'supervised_task': 'niche_classification',  # or whichever task\n",
    "    'extract_layers': [11],  # Which layers to extract features from\n",
    "    'function_layers': \"mean\",  # Architecture of prediction head\n",
    "    'dim_prediction': 33, # dim of the output vector\n",
    "    'n_classes': 1,  # only for classification tasks\n",
    "    'freeze': False,  # Whether to freeze backbone\n",
    "    'reinit_layers': False,\n",
    "    'extractor': False,\n",
    "    'regress_distribution': True,\n",
    "    'pool': 'mean',\n",
    "    'predict_density': False,\n",
    "    'ignore_zeros': False,\n",
    "    'organ': 'brain',\n",
    "    'label': 'cell_type'  # The target variable to predict\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology mean shape: (33502,)\n",
      "\n",
      "Total cells: 36,715\n",
      "Cell type counts:\n",
      "Rare classes (< 3 cells): 1\n",
      "cell_type\n",
      "bladder urothelial cell            22111\n",
      "fibroblast                          7227\n",
      "CD8-positive, alpha-beta T cell     2284\n",
      "monocyte                            1125\n",
      "myofibroblast cell                  1095\n",
      "macrophage                           725\n",
      "CD4-positive, alpha-beta T cell      421\n",
      "T cell                               412\n",
      "mast cell                            310\n",
      "smooth muscle cell                   271\n",
      "Name: count, dtype: int64\n",
      "Warning: Found 1 cell types with < 3 cells:\n",
      "  - endothelial cell: 1 cells\n",
      "Removing 1 cells from rare classes...\n",
      "Remaining cells: 36,714\n",
      "Remaining cell types: 20\n",
      "Created splits:\n",
      "  Train: 25,699 cells (70.0%)\n",
      "  Val:   5,507 cells (15.0%)\n",
      "  Test:  5,508 cells (15.0%)\n",
      "\n",
      "Split distribution by 'cell_type':\n",
      "cell_type          fibroblast  T cell  mast cell  myofibroblast cell  \\\n",
      "nicheformer_split                                                      \n",
      "test                     1084      62         47                 165   \n",
      "train                    5059     288        217                 766   \n",
      "val                      1084      62         46                 164   \n",
      "All                      7227     412        310                1095   \n",
      "\n",
      "cell_type          smooth muscle cell  erythrocyte  macrophage  B cell  \\\n",
      "nicheformer_split                                                        \n",
      "test                               41           16         109      15   \n",
      "train                             190           74         507      71   \n",
      "val                                40           16         109      16   \n",
      "All                               271          106         725     102   \n",
      "\n",
      "cell_type          monocyte  natural killer cell  ...  \\\n",
      "nicheformer_split                                 ...   \n",
      "test                    169                    5  ...   \n",
      "train                   787                   24  ...   \n",
      "val                     169                    5  ...   \n",
      "All                    1125                   34  ...   \n",
      "\n",
      "cell_type          CD8-positive, alpha-beta T cell  pericyte  neutrophil  \\\n",
      "nicheformer_split                                                          \n",
      "test                                           343        31           3   \n",
      "train                                         1599       141          18   \n",
      "val                                            342        30           4   \n",
      "All                                           2284       202          25   \n",
      "\n",
      "cell_type          plasma cell  mature NK T cell  \\\n",
      "nicheformer_split                                  \n",
      "test                         7                 2   \n",
      "train                       34                10   \n",
      "val                          7                 2   \n",
      "All                         48                14   \n",
      "\n",
      "cell_type          endothelial cell of lymphatic vessel  \\\n",
      "nicheformer_split                                         \n",
      "test                                                  7   \n",
      "train                                                35   \n",
      "val                                                   8   \n",
      "All                                                  50   \n",
      "\n",
      "cell_type          capillary endothelial cell  vein endothelial cell  \\\n",
      "nicheformer_split                                                      \n",
      "test                                        4                     18   \n",
      "train                                      19                     88   \n",
      "val                                         4                     19   \n",
      "All                                        27                    125   \n",
      "\n",
      "cell_type          bladder urothelial cell    All  \n",
      "nicheformer_split                                  \n",
      "test                                  3317   5508  \n",
      "train                                15477  25699  \n",
      "val                                   3317   5507  \n",
      "All                                  22111  36714  \n",
      "\n",
      "[4 rows x 21 columns]\n",
      "Final n_classes: 20\n"
     ]
    }
   ],
   "source": [
    "# Run this updated version to fix the rare class issue\n",
    "adata = ad.read_h5ad(config['data_path'])\n",
    "original_technology_mean = np.load(config['technology_mean_path'])\n",
    "from nicheformer.data.dataset import compute_technology_mean, create_splits\n",
    "\n",
    "# Compute new technology_mean\n",
    "technology_mean = compute_technology_mean(adata)\n",
    "print(f\"Technology mean shape: {technology_mean.shape}\")\n",
    "\n",
    "# Check distribution\n",
    "print(f\"\\nTotal cells: {len(adata):,}\")\n",
    "print(\"Cell type counts:\")\n",
    "counts = adata.obs['cell_type'].value_counts()\n",
    "print(f\"Rare classes (< 3 cells): {(counts < 3).sum()}\")\n",
    "print(counts.head(10))\n",
    "\n",
    "# Create splits with filtering\n",
    "adata = create_splits(\n",
    "    adata, \n",
    "    train_frac=0.7, \n",
    "    val_frac=0.15, \n",
    "    test_frac=0.15, \n",
    "    random_state=42, \n",
    "    stratify_col='cell_type',\n",
    "    min_cells_per_class=3\n",
    ")\n",
    "\n",
    "# Update config\n",
    "n_unique_cell_types = len(adata.obs['cell_type'].unique())\n",
    "config['n_classes'] = n_unique_cell_types\n",
    "print(f\"Final n_classes: {n_unique_cell_types}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train split with 25699 cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:40<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using val split with 5507 cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test split with 5508 cells\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Data and technology_mean are already loaded in the previous cell\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = NicheformerDataset(\n",
    "    adata=adata,\n",
    "    technology_mean=technology_mean,\n",
    "    split='train',\n",
    "    max_seq_len=1500,\n",
    "    aux_tokens=config.get('aux_tokens', 30),\n",
    "    chunk_size=config.get('chunk_size', 1000),\n",
    "    metadata_fields = {\n",
    "        'obs': ['cell_type'],\n",
    "    }\n",
    ")\n",
    "\n",
    "val_dataset = NicheformerDataset(\n",
    "    adata=adata,\n",
    "    technology_mean=technology_mean,\n",
    "    split='val',\n",
    "    max_seq_len=1500,\n",
    "    aux_tokens=config.get('aux_tokens', 30),\n",
    "    chunk_size=config.get('chunk_size', 1000),\n",
    "    metadata_fields = {\n",
    "        'obs': ['cell_type'],\n",
    "        #'obsm': ['X_niche_1'],\n",
    "    }\n",
    ")\n",
    "\n",
    "test_dataset = NicheformerDataset(\n",
    "    adata=adata,\n",
    "    technology_mean=technology_mean,\n",
    "    split='test',\n",
    "    max_seq_len=1500,\n",
    "    aux_tokens=config.get('aux_tokens', 30),\n",
    "    chunk_size=config.get('chunk_size', 1000),\n",
    "    metadata_fields = {\n",
    "        'obs': ['cell_type'],\n",
    "        #'obsm': ['X_niche_1'],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config.get('num_workers', 4),\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config.get('num_workers', 4),\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config.get('num_workers', 4),\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Set Up Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = Nicheformer.load_from_checkpoint(checkpoint_path=config['checkpoint_path'], strict=False)\n",
    "\n",
    "print(\"Model loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning model created\n"
     ]
    }
   ],
   "source": [
    "# Create fine-tuning model\n",
    "fine_tune_model = NicheformerFineTune(\n",
    "    backbone=model,\n",
    "    supervised_task=config['supervised_task'],\n",
    "    extract_layers=config['extract_layers'],\n",
    "    function_layers=config['function_layers'],\n",
    "    lr=config['lr'],\n",
    "    warmup=config['warmup'],\n",
    "    max_epochs=config['max_epochs'],\n",
    "    dim_prediction=config['dim_prediction'],\n",
    "    n_classes=config['n_classes'],\n",
    "    # baseline=config['baseline'],\n",
    "    freeze=False,\n",
    "    reinit_layers=config['reinit_layers'],\n",
    "    extractor=config['extractor'],\n",
    "    regress_distribution=config['regress_distribution'],\n",
    "    pool=config['pool'],\n",
    "    predict_density=config['predict_density'],\n",
    "    ignore_zeros=config['ignore_zeros'],\n",
    "    organ=config.get('organ', 'unknown'),\n",
    "    label=config['label'],\n",
    "    without_context=True\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone model hyperparameters:\n",
      "  modality: True\n",
      "  assay: True\n",
      "  specie: True\n",
      "Trainer created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/nicheformer_env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "# Check backbone model hyperparameters to understand the issue\n",
    "print(\"Backbone model hyperparameters:\")\n",
    "print(f\"  modality: {model.hparams.modality}\")\n",
    "print(f\"  assay: {model.hparams.assay}\")  \n",
    "print(f\"  specie: {model.hparams.specie}\")\n",
    "\n",
    "# Configure trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=config['max_epochs'],\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    default_root_dir=config['output_dir'],\n",
    "    precision=config.get('precision', 32),\n",
    "    gradient_clip_val=config.get('gradient_clip_val', 1.0),\n",
    "    accumulate_grad_batches=config.get('accumulate_grad_batches', 10),\n",
    ")\n",
    "\n",
    "print(\"Trainer created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 19 22:55:52 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.256.02   Driver Version: 470.256.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   48C    P0    42W / 300W |   1609MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    181205      C   ...icheformer_env/bin/python     1607MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name        | Type             | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | backbone    | Nicheformer      | 49.3 M | train\n",
      "1 | linear_head | Linear           | 10.2 K | train\n",
      "2 | cls_loss    | CrossEntropyLoss | 0      | train\n",
      "---------------------------------------------------------\n",
      "49.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "49.3 M    Total params\n",
      "197.249   Total estimated model params size (MB)\n",
      "144       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597a985ecfb94b03b7112f0be0160eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model  \n",
    "print(\"Training the model...\")\n",
    "try:\n",
    "    trainer.fit(\n",
    "        model=fine_tune_model,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=val_loader\n",
    "    )\n",
    "    \n",
    "    # Test the model\n",
    "    print(\"Testing the model...\")\n",
    "    test_results = trainer.test(\n",
    "        model=fine_tune_model,\n",
    "        dataloaders=test_loader\n",
    "    )\n",
    "    \n",
    "    # Get predictions\n",
    "    print(\"Getting predictions...\")\n",
    "    predictions = trainer.predict(fine_tune_model, dataloaders=test_loader)\n",
    "    predictions = [torch.cat([p[0] for p in predictions]).cpu().numpy(),\n",
    "                  torch.cat([p[1] for p in predictions]).cpu().numpy()]\n",
    "    if 'regression' in config['supervised_task']:\n",
    "        predictions = predictions[0]  # For regression both values are the same\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store predictions in AnnData object\n",
    "prediction_key = f\"predictions_{config.get('label', 'X_niche_1')}\"\n",
    "test_mask = adata.obs.nicheformer_split == 'test'\n",
    "\n",
    "if 'classification' in config['supervised_task']:\n",
    "    # For classification tasks\n",
    "    adata.obs.loc[test_mask, f\"{prediction_key}_class\"] = predictions[0]\n",
    "    adata.obs.loc[test_mask, f\"{prediction_key}_class_probs\"] = predictions[1]\n",
    "else:\n",
    "    # For regression tasks\n",
    "    adata.obs.loc[test_mask, prediction_key] = predictions\n",
    "\n",
    "# Store test metrics\n",
    "for metric_name, value in test_results[0].items():\n",
    "    adata.uns[f\"{prediction_key}_metrics_{metric_name}\"] = value\n",
    "\n",
    "# Save updated AnnData\n",
    "adata.write_h5ad(config['output_path'])\n",
    "\n",
    "print(f\"Results saved to {config['output_path']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
